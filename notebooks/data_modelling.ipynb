{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import preprocessing as prep\n",
    "import extraction as ext\n",
    "import yaml\n",
    "import importlib\n",
    "from pyspark.ml.feature import Normalizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Taxi Data\n",
      "Already downloaded file: yellow_tripdata_2017-01.parquet\n",
      "Already downloaded file: yellow_tripdata_2017-03.parquet\n",
      "Already downloaded file: yellow_tripdata_2017-06.parquet\n",
      "Already downloaded file: yellow_tripdata_2017-09.parquet\n",
      "Already downloaded file: yellow_tripdata_2017-11.parquet\n",
      "Already downloaded file: yellow_tripdata_2017-12.parquet\n",
      "Get zones\n",
      "Already downloaded file: taxi+_zone_lookup.csv\n",
      "Clean zones\n",
      "Add features taxi\n",
      "Clean Taxi Data\n",
      "SPDF Taxi size: 385696\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ext)\n",
    "importlib.reload(prep)\n",
    "\n",
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYC_Taxi\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")        \n",
    "spark.conf.set(\"spark.local.dir\", \"c:/tmp_spark\")      \n",
    "\n",
    "print(f\"Get Taxi Data\")\n",
    "psdf_taxi = ext.get_taxi_data(spark, cfg)\n",
    "\n",
    "print(f\"Get zones\")\n",
    "df_zones = ext.get_zones(cfg)\n",
    "print(f\"Clean zones\")\n",
    "df_zones = prep.clean_zone_data(df_zones)\n",
    "psdf_zones=spark.createDataFrame(df_zones)\n",
    "\n",
    "print(f\"Add features taxi\")\n",
    "psdf_taxi = prep.add_features_taxi_data(psdf_taxi, psdf_zones)\n",
    "\n",
    "print(f\"Clean Taxi Data\")\n",
    "psdf_taxi = prep.clean_taxi_data(psdf_taxi, cfg)\n",
    "\n",
    "print(f\"SPDF Taxi size: {psdf_taxi.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385696"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf_taxi.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "category_columns = [\"VendorID\", \n",
    "    # \"RateCodeID\", # adding this feature causes some surprising errors\n",
    "    \"store_and_fwd_flag\", \"payment_type\", \"pu_month\", \n",
    "    \"day_of_week\", \"hour\",\n",
    "    \"PU_Borough\", \"PU_Zone\", \"PU_service_zone\", \n",
    "    \"DO_Borough\", \"DO_Zone\", \"DO_service_zone\"]  \n",
    "\n",
    "indexer = StringIndexer(inputCols=category_columns, \n",
    "    outputCols=[column+\"_index\" for column in category_columns])    \n",
    "\n",
    "psdf_taxi_vec = indexer.fit(psdf_taxi).transform(psdf_taxi)\n",
    "\n",
    "ohe = OneHotEncoder(inputCols=[column+\"_index\" for column in category_columns], \n",
    "    outputCols=[column+\"_OHEVector\" for column in category_columns])\n",
    "\n",
    "psdf_taxi_vec = ohe.fit(psdf_taxi_vec).transform(psdf_taxi_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|tip_amount|\n",
      "+--------------------+----------+\n",
      "|(540,[0,1,3,5,6,7...|      1.96|\n",
      "|(540,[0,1,3,5,6,7...|      2.06|\n",
      "|(540,[0,1,2,3,5,6...|      2.06|\n",
      "|(540,[0,1,2,3,5,6...|      3.86|\n",
      "|(540,[0,1,3,5,6,7...|       0.0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# nummeric columns to normalize\n",
    "numeric_columns_norm = ['trip_distance', \n",
    "    'fare_amount', \n",
    "    'extra', 'mta_tax', 'tolls_amount',     \n",
    "    'total_amount','duration_in_min']\n",
    "\n",
    "# nummeric columns that we don't want to normalize\n",
    "numeric_columns = ['passenger_count']\n",
    "\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols = numeric_columns_norm,\n",
    "    outputCol = 'numeric_features')\n",
    "\n",
    "v_df = vectorAssembler.transform(psdf_taxi_vec)\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"numeric_features\", \n",
    "    outputCol=\"numeric_features_norm\")\n",
    "\n",
    "v_df = normalizer.transform(v_df)    \n",
    "\n",
    "category_columns_vec = [column+\"_OHEVector\" for column in category_columns]\n",
    "\n",
    "\n",
    "mergeAssembler = VectorAssembler(\n",
    "    inputCols = [\"numeric_features_norm\"] + numeric_columns + category_columns_vec,\n",
    "    outputCol = 'features')\n",
    "\n",
    "v_df = mergeAssembler.transform(v_df)\n",
    "v_df = v_df.select(['features', 'tip_amount'])\n",
    "v_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = v_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,-2.7029737234864695,0.0,-76.6537015053019,12.742659422544563,7.940613828161231,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6349673096372203,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.1850006949898113,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0368559803545105,0.0,0.0,-0.2911249049566416,0.0,0.0,0.0,0.0,1.1096928447845371,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.099641158372951,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.1096928447845371,1.329995565513778,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9495086883217558,0.0]\n",
      "Intercept: 0.9306767044828309\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', \n",
    "    labelCol='tip_amount', \n",
    "    maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.692485\n",
      "MSE: 2.864505\n",
      "r2: 0.581737\n",
      "MAPE: 0.873080\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"MSE: %f\" % trainingSummary.meanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n",
    "print(\"MAPE: %f\" % trainingSummary.meanAbsoluteError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.708766\n",
      "MSE: 2.919883\n",
      "r2: 0.576983\n",
      "MAPE: 0.877865\n"
     ]
    }
   ],
   "source": [
    "result = lr_model.evaluate(test_df)\n",
    "print(\"RMSE: %f\" % result.rootMeanSquaredError)\n",
    "print(\"MSE: %f\" % result.meanSquaredError)\n",
    "print(\"r2: %f\" % result.r2)\n",
    "print(\"MAPE: %f\" % result.meanAbsoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|       prediction|tip_amount|            features|\n",
      "+-----------------+----------+--------------------+\n",
      "|7.809769630059293|     12.57|(540,[0,1,2,3,4,5...|\n",
      "|5.886537428429102|      5.87|(540,[0,1,2,3,4,5...|\n",
      "| 7.43514567424946|      15.1|(540,[0,1,2,3,4,5...|\n",
      "|8.229743954628603|       7.0|(540,[0,1,2,3,4,5...|\n",
      "| 7.45153817606167|      7.57|(540,[0,1,2,3,4,5...|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"tip_amount\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.3073\n",
      "R Squared (R2) on test data = 0.752406\n",
      "Feature Importances\n",
      "(540,[0,1,2,3,4,5],[0.003131700654025644,0.031116799600539723,0.0007409679584589283,0.8219099475021654,0.004795826012293466,0.1383047582725167])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', \n",
    "    labelCol = 'tip_amount')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"tip_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "    labelCol=\"tip_amount\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(dt_predictions))\n",
    "\n",
    "print(\"Feature Importances\")\n",
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+--------------------+\n",
      "|        prediction|tip_amount|            features|\n",
      "+------------------+----------+--------------------+\n",
      "|11.758446210889097|     12.57|(540,[0,1,2,3,4,5...|\n",
      "| 6.049268188277188|      5.87|(540,[0,1,2,3,4,5...|\n",
      "| 9.508636887769553|      15.1|(540,[0,1,2,3,4,5...|\n",
      "| 9.298939161349207|       7.0|(540,[0,1,2,3,4,5...|\n",
      "|7.3786709514494335|      7.57|(540,[0,1,2,3,4,5...|\n",
      "+------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'tip_amount', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'tip_amount', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.980225\n",
      "R Squared (R2) on test data = 0.860798\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"tip_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "    labelCol=\"tip_amount\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(gbt_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8571e7f3e92f6e490cddd84ef78d4e4e0b96a1f565959148b10a39523fba88f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
